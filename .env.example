# Environment Configuration for NeMo-Charlie: DeepSeek-V3 Financial Trading Pipeline
# Copy this file to .env and fill in your values
# 
# This pipeline uses NVIDIA NeMo Framework for training DeepSeek-V3 models on financial data.
# See README.md for complete setup instructions.

# ====== API Configuration ======
# EODHD.com API key for financial price data (primary source)
# Get your free API key at: https://eodhd.com/
EODHD_API_KEY=your_eodhd_api_key_here

# ====== Dataset Time Splits ======
# Training data range (chronological split to prevent data leakage)
TRAIN_START_DATE=2023-10-24
TRAIN_END_DATE=2024-12-31

# Test data range (must be after training end date)
TEST_START_DATE=2025-01-01

# Validation split (days from end of training period)
# If not set, defaults to 30 days
VALIDATION_DAYS=30

# ====== Data Paths ======
# Input XML files containing financial theses
RAW_XML_DIR=data/raw_xml

# Converted JSONL output from XML parsing
JSONL_OUTPUT=data/jsonl/all.jsonl

# HuggingFace dataset directory (intermediate format)
HF_DATASET_DIR=data/hf_datasets/sft_dataset

# NeMo-compatible dataset directory (final training format)
NEMO_DATASET_DIR=data/nemo/sft_dataset

# Price data cache directory
PRICE_CACHE_DIR=data/price_cache

# ====== Model Configuration ======
# Base model for fine-tuning (DeepSeek-V3.2-Exp)
BASE_MODEL=deepseek-ai/DeepSeek-V3.2-Exp

# Maximum sequence length for training
MAX_LENGTH=65536

# Context window size
CONTEXT_WINDOW=131072

# ====== NeMo Training Configuration ======
# Output directory for trained models
OUTPUT_DIR=checkpoints/nemo_runs/main

# Number of training epochs
NUM_TRAIN_EPOCHS=2

# Learning rate (adjust based on peft setting)
LEARNING_RATE=1.5e-4

# Micro batch size per GPU
PER_DEVICE_TRAIN_BATCH_SIZE=1

# Gradient accumulation steps
GRADIENT_ACCUMULATION_STEPS=16

# NeMo template format (chatml, alpaca, simple)
NEMO_TEMPLATE=chatml

# ====== Model Conversion Paths ======
# Source DeepSeek-V3 FP8 model directory
MODEL_SOURCE_DIR=/data/models/deepseek-v3-source

# Converted BF16 model directory
MODEL_BF16_DIR=/data/models/deepseek-v3-bf16

# Final NeMo .nemo archive path
MODEL_NEMO_PATH=/data/models/deepseek-v3-base_tp8_pp1.nemo

# ====== Evaluation Configuration ======
# Forward return windows for financial evaluation (days)
FORWARD_WINDOWS=1,5,10,30

# Results directory
RESULTS_DIR=results

# Evaluation results CSV file
EVAL_RESULTS_CSV=results/eval_results.csv

# ====== Logging & Monitoring ======
# Log directory
LOG_DIR=logs

# Weights & Biases integration
USE_WANDB=false
WANDB_PROJECT=NeMo-Charlie-Trading
WANDB_ENTITY=your_wandb_entity

# ====== Reproducibility ======
# Random seed for reproducibility
SEED=42

# Git repository path (for manifest generation)
GIT_REPO=/opt/NeMo-Charlie

# ====== Testing & Development ======
# Enable smoke test mode (smaller datasets, faster execution)
SMOKE_TEST_MODE=false

# Number of samples for smoke testing
SMOKE_TEST_SAMPLES=10

# CPU-only mode (for development without GPU)
CPU_ONLY_MODE=false

# ====== Hardware Configuration ======
# Number of GPUs per node (for NeMo training)
GPUS_PER_NODE=8

# Number of nodes (for distributed training)
NUM_NODES=1

# ====== Optional: Advanced Configuration ======
# Enable gradient checkpointing to save memory
GRADIENT_CHECKPOINTING=true

# Mixed precision training
USE_FP16=true

# Enable flash attention (if available)
USE_FLASH_ATTENTION=false
